{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "16b2c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %pip install llama-index-vector-stores-lancedb\n",
    "# %pip install llama-index-multi-modal-llms-openai\n",
    "# %pip install llama-index-embeddings-clip\n",
    "# %pip install git+https://github.com/openai/CLIP.git\n",
    "# %pip install llama-index-readers-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f37f0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install llama_index\n",
    "# %pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29af5eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install lancedb\n",
    "# %pip install moviepy\n",
    "# %pip install pytube\n",
    "# %pip install pydub\n",
    "# %pip install SpeechRecognition\n",
    "# %pip install ffmpeg-python\n",
    "# %pip install soundfile\n",
    "# %pip install torch torchvision\n",
    "# %pip install matplotlib scikit-image\n",
    "# %pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"****************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "93e4d434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "681a3b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "672aa7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy import VideoFileClip\n",
    "from pathlib import Path\n",
    "import speech_recognition as sr\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cd93676f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PREET\\OneDrive\\Desktop\\GENRATIVE-AI\\Multimodeel_RAG\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "effd2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_url=\"https://www.youtube.com/watch?v=Vej327jN8WI\"\n",
    "output_video_path = \"../Multimodeel_RAG/content/video_data/\"\n",
    "     \n",
    "# from the video i am going to collect images,audio,text\n",
    "output_folder = \"../Multimodeel_RAG/content/mixed_data/\"\n",
    "output_audio_path = \"../Multimodeel_RAG/content/mixed_data/output_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "adfc799a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Multimodeel_RAG/content/video_data/Worker Threads in Node.jsï¼š The Secret to High-Performance Backends ðŸ”¥.mp4\n"
     ]
    }
   ],
   "source": [
    "filepath = output_video_path + \"Worker Threads in Node.jsï¼š The Secret to High-Performance Backends ðŸ”¥.mp4\"\n",
    "\n",
    "print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "04841769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "baefbb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import os\n",
    "import re\n",
    "\n",
    "def download_video_ytdlp(url, output_path):\n",
    "    # Basic URL validation for YouTube videos\n",
    "    if not re.match(r'https?://(www\\.)?youtube\\.com/watch\\?v=[a-zA-Z0-9_-]+(&.*)?$', url) and \\\n",
    "       not re.match(r'https?://youtu\\.be/[a-zA-Z0-9_-]+', url):\n",
    "        print(\"Invalid YouTube URL format.\")\n",
    "        print(\"Please provide a valid YouTube video URL (e.g., https://www.youtube.com/watch?v=JR36oH35Fgg).\")\n",
    "        return\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "        print(f\"Created output folder: '{output_path}'\")\n",
    "\n",
    "    ffmpeg_bin_path = r'C:\\FFmpeg\\bin' \n",
    "\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best', # Prioritize MP4, then best overall\n",
    "        'outtmpl': os.path.join(output_path, '%(title)s.%(ext)s'), # Output file name template\n",
    "        'noplaylist': True, # Only download the single video if a playlist URL is given\n",
    "        'progress_hooks': [lambda d: print(f\"Status: {d['status']} - {d.get('filename', '')} - {d.get('_percent_str', '')}\") if 'status' in d else None],\n",
    "        'ffmpeg_location': ffmpeg_bin_path,\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            # Get video information without downloading first\n",
    "            info_dict = ydl.extract_info(url, download=False)\n",
    "            video_title = info_dict.get('title', 'Unknown Title')\n",
    "            print(f\"Attempting to download: {video_title}\")\n",
    "\n",
    "            # Now, proceed with the download\n",
    "            ydl.download([url])\n",
    "            print(f\"Download of '{video_title}' completed successfully.\")\n",
    "\n",
    "    except yt_dlp.utils.DownloadError as e:\n",
    "        print(f\"Error downloading video: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dd0842f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Vej327jN8WI\n",
      "[youtube] Vej327jN8WI: Downloading webpage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Vej327jN8WI: Downloading tv client config\n",
      "[youtube] Vej327jN8WI: Downloading tv player API JSON\n",
      "[youtube] Vej327jN8WI: Downloading ios player API JSON\n",
      "[youtube] Vej327jN8WI: Downloading m3u8 information\n",
      "Attempting to download: Worker Threads in Node.js: The Secret to High-Performance Backends ðŸ”¥\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=Vej327jN8WI\n",
      "[youtube] Vej327jN8WI: Downloading webpage\n",
      "[youtube] Vej327jN8WI: Downloading tv client config\n",
      "[youtube] Vej327jN8WI: Downloading tv player API JSON\n",
      "[youtube] Vej327jN8WI: Downloading ios player API JSON\n",
      "[youtube] Vej327jN8WI: Downloading m3u8 information\n",
      "[info] Vej327jN8WI: Downloading 1 format(s): 616+140-8\n",
      "[download] ..\\Multimodeel_RAG\\content\\video_data\\Worker Threads in Node.jsï¼š The Secret to High-Performance Backends ðŸ”¥.mp4 has already been downloaded\n",
      "Download of 'Worker Threads in Node.js: The Secret to High-Performance Backends ðŸ”¥' completed successfully.\n"
     ]
    }
   ],
   "source": [
    "metadata_vid = download_video_ytdlp(video_url, output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "5129c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_images(video_path,output_folder):\n",
    "  clip=VideoFileClip(video_path)\n",
    "  clip.write_images_sequence(\n",
    "      os.path.join(output_folder,\"frame%04d.png\"),fps=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5acbc34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.youtube.com/watch?v=Vej327jN8WI'"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "84f88810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    }
   ],
   "source": [
    "video_to_images(filepath,output_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "90ab9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_audio(video_path,output_audio_path):\n",
    "  clip=VideoFileClip(video_path)\n",
    "  audio=clip.audio\n",
    "  audio.write_audiofile(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "528609f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ../Multimodeel_RAG/content/mixed_data/output_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "video_to_audio(filepath,output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3bee02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_text(audio_path):\n",
    "  recognizer=sr.Recognizer()\n",
    "  audio=sr.AudioFile(audio_path)\n",
    "\n",
    "  with audio as source:\n",
    "    audio_data=recognizer.record(source)\n",
    "\n",
    "    try:\n",
    "\n",
    "      #recognize the speech\n",
    "      text = recognizer.recognize_whisper(audio_data)\n",
    "\n",
    "    except sr.UnknownValueError:\n",
    "      print(\"Speech recognition could not understand the audio.\")\n",
    "  return text\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "61d8d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = audio_to_text(output_audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "8654f83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" In the last video, we explored how Node.js uses a single thread model with an event loop to efficiently handle IOTask, like reading files, making network request or querying databases without blocking the main thread. But we also saw its limitation. CPU intensive tasks like data processing, image manipulation or encryption can block the event loop, making the entire application unresponsive. And that's where worker threads come in. In this video, we are going one level deeper. We'll break down what worker threads are, how they bring true parallelism to Node.js, and how you can use them to offload CPU heavy operations without slowing down your app. We'll look at how they work under the hood, where to use them and walk through a real code example. So let's get started and see how mild threading in Node.js actually works. Before we jump into worker threads, let's clear something up. By default, Node.js runs on a single thread, meaning it can only execute one JavaScript task at a time. But it hinders IO heavy workloads efficiently, thanks to LibUV, which offloads time-consuming operations like file system access to its internal thread pool. So, even though Node.js is single threaded at the JavaScript level, it does use threads behind the scenes. LibUV powers Node.js's asynchronous behavior. It all starts with the call stack. Your JavaScript code runs here, one task at a time. When it encounters an IO operation like reading a file or hashing a password, Node.js registers that IO. The IO task is handed off to LibUV, which manages the async work behind the scenes. LibUV places the IO task into its task queue, and then, one of the threads in LibUV's thread pool, usually 4 threads by default, picks up the task and processes it in the background. These threads do not run your JavaScript logic. They are purely for handling system level operations like disk or network access. Once the task is complete, LibUV uses even the multiplexer to notify the system that the IO is done. The event look picks up the completed task from the event queue, and finally, the callback associated with the IO operation is sent back to the call stack to be executed by the V8 engine. And this is how Node.js, despite being single threaded, can handle IO heavy task workloads without blocking the main thread. Thanks to LibUV and its internal thread pool. So, when performing IO tasks like database queries or API calls, for example, reading files, Node.js offloads such tasks to the system kernel, or the operating system, allowing other tasks to run while waiting for IO tasks to complete. This code here is non-blocking because fs.read file is handled by the operating system in a separate IO thread. While the OS is reading the file, the event look remains free to process the request or task. And when the file is ready, Node.js picks up the results and resumes execution. Let's quickly understand what's happening here. AsyncAveT here is a JavaScript modern way of writing asynchronous code that looks and reads like regular synchronous code. It makes code cleaner and easier to follow. No more nested callbacks or complex.thenchains. I'll explain how AsyncAveT works in depth in a future video, but for now, here is what you need to know. The code is non-blocking. The line, awaitfs.read file, tells Node.js, hey, pause this function here, but don't block the rest of the program. And behind the scenes, Node.js sends the file reading task to live you with thread pool. While the file is being read, the event look continues. So we immediately see subscribing to bytemark printed. Once the file is ready, the Async function resumes execution, printing the file content and completion message. So even with just one thread, Node.js feels fast and responsive, thanks to non-blocking IO and AsyncAveT. It manages a pool of threads, usually 4x default, and uses them to offload slow system level operations like reading or writing files, performing cryptographic operations, DNS lookups, compression, etc. These tasks are written in C or C++ and live you via executes them in the background, away from the main thread. Once done, the results are pushed back to the event look, so your JavaScript code can continue. And yes, Node.js itself is single threaded, but the library is it uses internally such as live you via with its thread pool for some IO operations are not. The thread pool in conjunction with the task queue is used to handle blocking IO operations. By default, the thread pool includes 4 threads, but this behavior can be modified by providing additional environment variable. But, and this is the key, these live you via threads do not run your custom JavaScript code. For example, here we are summing numbers from 0 to 1 billion, a classic CPU heavy task. Even though it's just a fur loop, this operation consumes a lot of processing time, and since it's running on the main thread, nothing else can happen in the meantime. And that is why, subscribing to bytemunk is delayed until the loop completes. And this clearly shows that your JavaScript logic like math operation, loops or JSON parsing runs on the main thread. Live you as background threads won't help you, because this isn't IO, and that brings us to the real solution for CPU heavy JavaScript task. The worker threads. Worker threads allow you to run JavaScript code in parallel, on separate threads, without blocking the main event loop. You can think of them as many not just environments, running in the background, each with their own memory and event loop. So while your main thread keeps serving users, a worker thread can handle the heavy lifting behind the scenes. So here in main jails, we define a function called as run worker, that creates a new worker threads and points it to worker.js. This worker runs in a separate thread, fully independent from the main thread. We wrap this in a promise, so we can use it with async await and listen for two events. When the worker finishes and sends back a result via message, we resolve the promise. And if something goes wrong, we catch it with error. In the main function, we await run worker. We start the worker and wait for the results without blocking the main thread. Now look at the line right after that. Console.log subscribing to whitemark. Even though we are doing a CPU heavy task, something number of the billion, the main thread doesn't freeze. That line runs immediately, showing that our app stays responsive and snappy. Meanwhile, inside worker.js, we simulate a heavy computation, adding up numbers from one to a billion, and send the final result back using parent port.postmessage. And this is the real power of worker threads. You can offload CPU heavy JavaScript logic, run it in parallel, and keep your main thread light and fast. So, if you are building apps with heavy computation, worker threads are a game changer. They let you tap into true parallelism without switching languages or giving up the simplicity of JavaScript. And if you found this video helpful, don't forget to like the video, subscribe to whitemark and hit the bell icon. So, you never miss an update. And if you got more video ideas, drop them in the comments. I would love to help. Thanks for watching and I'll see you in the next one.\""
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "117f341f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text data saved to file\n"
     ]
    }
   ],
   "source": [
    "with open(output_folder + \"output_text.txt\", \"w\") as file:\n",
    "        file.write(text_data)\n",
    "print(\"Text data saved to file\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "178804a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file removed\n"
     ]
    }
   ],
   "source": [
    "os.remove(output_audio_path)\n",
    "print(\"Audio file removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b09582cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process the video\n",
    "#image\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "56869958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "9c6e9b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.lancedb import LanceDBVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b6663124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Table image_collection doesn't exist yet. Please add some data to create it.\n"
     ]
    }
   ],
   "source": [
    "text_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"text_collection\")\n",
    "image_store=LanceDBVectorStore(uri=\"lancedb\",table_name=\"image_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "59f9c6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageContext(docstore=<llama_index.core.storage.docstore.simple_docstore.SimpleDocumentStore object at 0x000001996DA7EA30>, index_store=<llama_index.core.storage.index_store.simple_index_store.SimpleIndexStore object at 0x000001996DA7E070>, vector_stores={'default': LanceDBVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=True, uri='lancedb', vector_column_name='vector', nprobes=20, refine_factor=None, text_key='text', doc_id_key='doc_id', api_key=None, region=None, mode='overwrite', query_type='vector', overfetch_factor=1), 'image': LanceDBVectorStore(stores_text=True, is_embedding_query=True, flat_metadata=True, uri='lancedb', vector_column_name='vector', nprobes=20, refine_factor=None, text_key='text', doc_id_key='doc_id', api_key=None, region=None, mode='overwrite', query_type='vector', overfetch_factor=1)}, graph_store=<llama_index.core.graph_stores.simple.SimpleGraphStore object at 0x000001996DA7E310>, property_graph_store=None)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "storage_context=StorageContext.from_defaults(vector_store=text_store,image_store=image_store)\n",
    "\n",
    "storage_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad5d74ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=SimpleDirectoryReader(output_folder).load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a4105891",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = MultiModalVectorStoreIndex.from_documents(documents,storage_context=storage_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "26b51644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.multi_modal.retriever.MultiModalVectorIndexRetriever at 0x1996b0c1c70>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_engine=index.as_retriever(similarity_top_k=1, image_similarity_top_k=10)\n",
    "\n",
    "\n",
    "retriever_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bd2bf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import ImageNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "137d9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(retriever_engine, query_str):\n",
    "    retrieval_results = retriever_engine.retrieve(query_str)\n",
    "\n",
    "    retrieved_image = []\n",
    "    retrieved_text = []\n",
    "    for res_node in retrieval_results:\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retrieved_image.append(res_node.node.metadata[\"file_path\"])\n",
    "        else:\n",
    "            display_source_node(res_node, source_length=200)\n",
    "            retrieved_text.append(res_node.text)\n",
    "\n",
    "    return retrieved_image, retrieved_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "d110d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"can you tell me about node js worker threead\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "d8cf1f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Node ID:** 3bd6b16a-3ba5-4ec6-a942-b59d926922ff<br>**Similarity:** 0.6903516054153442<br>**Text:** So we immediately see subscribing to bytemark printed. Once the file is ready, the Async function resumes execution, printing the file content and completion message. So even with just one thread, ...<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img,text=retrieve(retriever_engine,query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "8c2576eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_images(images_path):\n",
    "  images_shown = 0\n",
    "  plt.figure(figsize=(16, 9))\n",
    "  for img_path in images_path:\n",
    "        if os.path.isfile(img_path):\n",
    "            image = Image.open(img_path)\n",
    "\n",
    "            plt.subplot(2, 3, images_shown + 1)\n",
    "            plt.imshow(image)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "            images_shown += 1\n",
    "            if images_shown >= 5:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "518a633a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_images(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9eac586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl_str=(\n",
    "    \"Based on the provided information, including relevant images and retrieved context from the video, \\\n",
    "    accurately and precisely answer the query without any additional prior knowledge.\\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Context: {context_str}\\n\"\n",
    "    \"Metadata for video: {metadata_str} \\n\"\n",
    "\n",
    "    \"---------------------\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "96a5e487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e904c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "metadata_str=json.dumps(metadata_vid)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "149752a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str=\"can you tell me about node js worker threead\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "30ab5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_str = \"\".join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "fbeee9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade pytube\n",
    "# %pip install yt-dlp\n",
    "# %pip show pytube\n",
    "# %pip install git+https://github.com/pytube/pytube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5d509470",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must provide either `input_dir` or `input_files`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[213], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m image_documents \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleDirectoryReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mload_data()\n",
      "File \u001b[1;32mc:\\Users\\PREET\\OneDrive\\Desktop\\GENRATIVE-AI\\QuestionAnswer-System\\venv\\lib\\site-packages\\llama_index\\core\\readers\\file\\base.py:270\u001b[0m, in \u001b[0;36mSimpleDirectoryReader.__init__\u001b[1;34m(self, input_dir, input_files, exclude, exclude_hidden, exclude_empty, errors, recursive, encoding, filename_as_id, required_exts, file_extractor, num_files_limit, file_metadata, raise_on_error, fs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_dir \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m input_files:\n\u001b[1;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide either `input_dir` or `input_files`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs \u001b[38;5;241m=\u001b[39m fs \u001b[38;5;129;01mor\u001b[39;00m get_default_fs()\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m errors\n",
      "\u001b[1;31mValueError\u001b[0m: Must provide either `input_dir` or `input_files`."
     ]
    }
   ],
   "source": [
    "\n",
    "image_documents = SimpleDirectoryReader( input_files=img).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc16c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e04bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_mm_llm = OpenAIMultiModal(model=\"gpt-4-vision-preview\", api_key=\"*****************************\", max_new_tokens=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc8cfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'context_str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m openai_mm_llm\u001b[38;5;241m.\u001b[39mcomplete(\n\u001b[1;32m----> 2\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[43mqa_tmpl_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmetadata_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_str\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# image_documents=image_documents,\u001b[39;00m\n\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'context_str'"
     ]
    }
   ],
   "source": [
    "\n",
    "result = openai_mm_llm.complete(\n",
    "    prompt=qa_tmpl_str.format(\n",
    "        query_str=query_str,metadata_str=metadata_str\n",
    "    )\n",
    "    # image_documents=image_documents,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcace5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3b143e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c32bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d360ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
